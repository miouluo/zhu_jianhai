{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# Viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "\n",
    "# Modeling \n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cluster, accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV, cross_val_score, StratifiedKFold, GroupKFold\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from colorama import Fore, Back, Style\n",
    "# Other\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:22.642275Z",
     "iopub.execute_input": "2022-08-27T11:12:22.642828Z",
     "iopub.status.idle": "2022-08-27T11:12:23.470782Z",
     "shell.execute_reply.started": "2022-08-27T11:12:22.642740Z",
     "shell.execute_reply": "2022-08-27T11:12:23.469708Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load Data\n",
    "train = pd.read_csv('../input/tabular-playground-series-aug-2022/train.csv')\n",
    "test = pd.read_csv('../input/tabular-playground-series-aug-2022/test.csv')\n",
    "sample_submission = pd.read_csv('../input/tabular-playground-series-aug-2022/sample_submission.csv')\n",
    "target = train['failure']\n",
    "test['failure'] = 1\n",
    "test_target = test['failure'] \n",
    "train.drop('failure',axis=1, inplace = True)\n",
    "test.drop('failure',axis=1, inplace = True)\n",
    "data = pd.concat([train, test])\n",
    "train.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:23.472706Z",
     "iopub.execute_input": "2022-08-27T11:12:23.473069Z",
     "iopub.status.idle": "2022-08-27T11:12:23.739325Z",
     "shell.execute_reply.started": "2022-08-27T11:12:23.473040Z",
     "shell.execute_reply": "2022-08-27T11:12:23.738235Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-Processing "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "data['m3_missing'] = data['measurement_3'].isnull().astype(np.int8)\n",
    "data['m5_missing'] = data['measurement_5'].isnull().astype(np.int8)\n",
    "#特征组合\n",
    "data['area'] = data['attribute_2'] * data['attribute_3']\n",
    "feature = [f for f in test.columns if f.startswith('measurement') or f=='loading']"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:23.740605Z",
     "iopub.execute_input": "2022-08-27T11:12:23.741293Z",
     "iopub.status.idle": "2022-08-27T11:12:23.751220Z",
     "shell.execute_reply.started": "2022-08-27T11:12:23.741254Z",
     "shell.execute_reply": "2022-08-27T11:12:23.750197Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data['attribute_2']"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:23.753874Z",
     "iopub.execute_input": "2022-08-27T11:12:23.754261Z",
     "iopub.status.idle": "2022-08-27T11:12:23.764262Z",
     "shell.execute_reply.started": "2022-08-27T11:12:23.754224Z",
     "shell.execute_reply": "2022-08-27T11:12:23.763343Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "feature"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:23.765948Z",
     "iopub.execute_input": "2022-08-27T11:12:23.766349Z",
     "iopub.status.idle": "2022-08-27T11:12:23.773334Z",
     "shell.execute_reply.started": "2022-08-27T11:12:23.766312Z",
     "shell.execute_reply": "2022-08-27T11:12:23.772285Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# dictionnary of dictionnaries (for the 11 best correlated measurement columns), \n",
    "# we will use the dictionnaries below to select the best correlated columns according to the product code)\n",
    "# Only for 'measurement_17' we make a 'manual' selection :\n",
    "full_fill_dict ={}\n",
    "full_fill_dict['measurement_17'] = {\n",
    "    'A': ['measurement_5','measurement_6','measurement_8'],\n",
    "    'B': ['measurement_4','measurement_5','measurement_7'],\n",
    "    'C': ['measurement_5','measurement_7','measurement_8','measurement_9'],\n",
    "    'D': ['measurement_5','measurement_6','measurement_7','measurement_8'],\n",
    "    'E': ['measurement_4','measurement_5','measurement_6','measurement_8'],\n",
    "    'F': ['measurement_4','measurement_5','measurement_6','measurement_7'],\n",
    "    'G': ['measurement_4','measurement_6','measurement_8','measurement_9'],\n",
    "    'H': ['measurement_4','measurement_5','measurement_7','measurement_8','measurement_9'],\n",
    "    'I': ['measurement_3','measurement_7','measurement_8']\n",
    "}"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:23.777208Z",
     "iopub.execute_input": "2022-08-27T11:12:23.777495Z",
     "iopub.status.idle": "2022-08-27T11:12:23.785638Z",
     "shell.execute_reply.started": "2022-08-27T11:12:23.777470Z",
     "shell.execute_reply": "2022-08-27T11:12:23.784635Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "col = [col for col in test.columns if 'measurement' not in col]+ ['loading','m3_missing','m5_missing']\n",
    "col"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:23.787360Z",
     "iopub.execute_input": "2022-08-27T11:12:23.787993Z",
     "iopub.status.idle": "2022-08-27T11:12:23.799319Z",
     "shell.execute_reply.started": "2022-08-27T11:12:23.787958Z",
     "shell.execute_reply": "2022-08-27T11:12:23.798340Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "col = [col for col in test.columns if 'measurement' not in col]+ ['loading','m3_missing','m5_missing']\n",
    "a = []\n",
    "b =[]\n",
    "for x in range(3,17):\n",
    "    corr = np.absolute(data.drop(col, axis=1).corr()[f'measurement_{x}']).sort_values(ascending=False)\n",
    "    a.append(np.round(np.sum(corr[1:4]),3)) \n",
    "    b.append(f'measurement_{x}')\n",
    "c = pd.DataFrame()\n",
    "c['Selected columns'] = b\n",
    "c['correlation total'] = a\n",
    "c = c.sort_values(by = 'correlation total',ascending=False).reset_index(drop = True)\n",
    "print(f'Columns selected by correlation sum of the 3 first rows : ')\n",
    "display(c.head(10))\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:23.801091Z",
     "iopub.execute_input": "2022-08-27T11:12:23.801785Z",
     "iopub.status.idle": "2022-08-27T11:12:24.491716Z",
     "shell.execute_reply.started": "2022-08-27T11:12:23.801750Z",
     "shell.execute_reply": "2022-08-27T11:12:24.490728Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x = 3\n",
    "corr = np.absolute(data.drop(col, axis=1).corr()[f'measurement_{x}']).sort_values(ascending=False)\n",
    "corr"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:24.493088Z",
     "iopub.execute_input": "2022-08-27T11:12:24.494029Z",
     "iopub.status.idle": "2022-08-27T11:12:24.553394Z",
     "shell.execute_reply.started": "2022-08-27T11:12:24.493988Z",
     "shell.execute_reply": "2022-08-27T11:12:24.552374Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "c"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:24.557417Z",
     "iopub.execute_input": "2022-08-27T11:12:24.557759Z",
     "iopub.status.idle": "2022-08-27T11:12:24.569288Z",
     "shell.execute_reply.started": "2022-08-27T11:12:24.557719Z",
     "shell.execute_reply": "2022-08-27T11:12:24.568217Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "full_fill_dict"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:24.570928Z",
     "iopub.execute_input": "2022-08-27T11:12:24.572180Z",
     "iopub.status.idle": "2022-08-27T11:12:24.580807Z",
     "shell.execute_reply.started": "2022-08-27T11:12:24.572105Z",
     "shell.execute_reply": "2022-08-27T11:12:24.579649Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i in range(10):\n",
    "    measurement_col = 'measurement_' + c.iloc[i,0][12:] # we select the next best correlated column \n",
    "    fill_dict ={}\n",
    "    for x in data.product_code.unique() : \n",
    "        corr = np.absolute(data[data.product_code == x].drop(col, axis=1).corr()[measurement_col]).sort_values(ascending=False)\n",
    "        measurement_col_dic = {}\n",
    "        measurement_col_dic[measurement_col] = corr[1:5].index.tolist()\n",
    "        fill_dict[x] = measurement_col_dic[measurement_col]\n",
    "    full_fill_dict[measurement_col] =fill_dict"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:24.582421Z",
     "iopub.execute_input": "2022-08-27T11:12:24.583715Z",
     "iopub.status.idle": "2022-08-27T11:12:25.516606Z",
     "shell.execute_reply.started": "2022-08-27T11:12:24.583476Z",
     "shell.execute_reply": "2022-08-27T11:12:25.515641Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "feature = [f for f in data.columns if f.startswith('measurement') or f=='loading']\n",
    "nullValue_cols = [col for col in train.columns if train[col].isnull().sum()!=0]\n",
    "    \n",
    "for code in data.product_code.unique():\n",
    "    total_na_filled_by_linear_model = 0\n",
    "    print(f'\\n-------- Product code {code} ----------\\n')\n",
    "    print(f'filled by linear model :')\n",
    "    for measurement_col in list(full_fill_dict.keys()):\n",
    "        \n",
    "        \n",
    "        tmp = data[data.product_code==code]\n",
    "        column = full_fill_dict[measurement_col][code] #top n most relevence featutes\n",
    "        tmp_train = tmp[column+[measurement_col]].dropna(how='any')\n",
    "        tmp_test = tmp[(tmp[column].isnull().sum(axis=1)==0)&(tmp[measurement_col].isnull())]\n",
    "\n",
    "        model = HuberRegressor(epsilon=1.9)\n",
    "        model.fit(tmp_train[column], tmp_train[measurement_col])\n",
    "        data.loc[(data.product_code==code)&(data[column].isnull().sum(axis=1)==0)&(data[measurement_col].isnull()),measurement_col] = model.predict(tmp_test[column])\n",
    "        \n",
    "        total_na_filled_by_linear_model += len(tmp_test)\n",
    "        \n",
    "    # others NA columns:\n",
    "    NA = data.loc[data[\"product_code\"] == code,nullValue_cols ].isnull().sum().sum()\n",
    "    model1 = KNNImputer(n_neighbors=3)\n",
    "    data.loc[data.product_code==code, feature] = model1.fit_transform(data.loc[data.product_code==code, feature])\n",
    "    print(f'\\n{total_na_filled_by_linear_model} filled by linear model ') \n",
    "    print(f'{NA} filled by KNN ')\n",
    "    \n",
    "data['measurement_avg'] = data[[f'measurement_{i}' for i in range(3, 17)]].mean(axis=1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:25.518327Z",
     "iopub.execute_input": "2022-08-27T11:12:25.518844Z",
     "iopub.status.idle": "2022-08-27T11:12:43.111073Z",
     "shell.execute_reply.started": "2022-08-27T11:12:25.518798Z",
     "shell.execute_reply": "2022-08-27T11:12:43.110081Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "float_cols = [col for col in train.columns if train[col].dtypes == 'float64']"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:43.112613Z",
     "iopub.execute_input": "2022-08-27T11:12:43.113228Z",
     "iopub.status.idle": "2022-08-27T11:12:43.118972Z",
     "shell.execute_reply.started": "2022-08-27T11:12:43.113190Z",
     "shell.execute_reply": "2022-08-27T11:12:43.118073Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i in float_cols:\n",
    "    train[i] = train[i].apply(lambda x:np.log(x+1))\n",
    "    test[i] = test[i].apply(lambda x:np.log(x+1))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:43.120408Z",
     "iopub.execute_input": "2022-08-27T11:12:43.120753Z",
     "iopub.status.idle": "2022-08-27T11:12:43.942021Z",
     "shell.execute_reply.started": "2022-08-27T11:12:43.120719Z",
     "shell.execute_reply": "2022-08-27T11:12:43.941061Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install feature_engine\n",
    "from feature_engine.encoding import WoEEncoder"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:43.943324Z",
     "iopub.execute_input": "2022-08-27T11:12:43.944110Z",
     "iopub.status.idle": "2022-08-27T11:12:55.294679Z",
     "shell.execute_reply.started": "2022-08-27T11:12:43.944070Z",
     "shell.execute_reply": "2022-08-27T11:12:55.293580Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_id = data['id']\n",
    "data.drop(columns=['id'], inplace=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:55.297418Z",
     "iopub.execute_input": "2022-08-27T11:12:55.298515Z",
     "iopub.status.idle": "2022-08-27T11:12:55.317213Z",
     "shell.execute_reply.started": "2022-08-27T11:12:55.298481Z",
     "shell.execute_reply": "2022-08-27T11:12:55.316157Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:55.320681Z",
     "iopub.execute_input": "2022-08-27T11:12:55.320973Z",
     "iopub.status.idle": "2022-08-27T11:12:55.364314Z",
     "shell.execute_reply.started": "2022-08-27T11:12:55.320948Z",
     "shell.execute_reply": "2022-08-27T11:12:55.363342Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data['attribute_2'] = data['attribute_2'].apply(lambda x: str(x))\n",
    "data['attribute_3'] = data['attribute_3'].apply(lambda x: str(x))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:55.365920Z",
     "iopub.execute_input": "2022-08-27T11:12:55.366668Z",
     "iopub.status.idle": "2022-08-27T11:12:55.403420Z",
     "shell.execute_reply.started": "2022-08-27T11:12:55.366631Z",
     "shell.execute_reply": "2022-08-27T11:12:55.402517Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "NUMERIC_FEATURE_NAMES = ['loading', 'measurement_0', 'measurement_1', 'measurement_2',\n",
    "       'measurement_3', 'measurement_4', 'measurement_5', 'measurement_6',\n",
    "       'measurement_7', 'measurement_8', 'measurement_9', 'measurement_10',\n",
    "       'measurement_11', 'measurement_12', 'measurement_13', 'measurement_14',\n",
    "       'measurement_15', 'measurement_16', 'measurement_17', 'm3_missing',\n",
    "       'm5_missing', 'area', 'measurement_avg']\n",
    "for i in  NUMERIC_FEATURE_NAMES:\n",
    "    data[i] = data[i].apply(lambda x:np.float32(x))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:55.404918Z",
     "iopub.execute_input": "2022-08-27T11:12:55.405602Z",
     "iopub.status.idle": "2022-08-27T11:12:56.095073Z",
     "shell.execute_reply.started": "2022-08-27T11:12:55.405566Z",
     "shell.execute_reply": "2022-08-27T11:12:56.094091Z"
    },
    "trusted": true
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train = data.iloc[:train.shape[0],:]\n",
    "test = data.iloc[train.shape[0]:,:]\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "groups = train.product_code\n",
    "X = train\n",
    "y = target"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:56.096370Z",
     "iopub.execute_input": "2022-08-27T11:12:56.097458Z",
     "iopub.status.idle": "2022-08-27T11:12:56.105830Z",
     "shell.execute_reply.started": "2022-08-27T11:12:56.097418Z",
     "shell.execute_reply": "2022-08-27T11:12:56.104671Z"
    },
    "trusted": true
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X.columns"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:56.107558Z",
     "iopub.execute_input": "2022-08-27T11:12:56.108180Z",
     "iopub.status.idle": "2022-08-27T11:12:56.116244Z",
     "shell.execute_reply.started": "2022-08-27T11:12:56.108135Z",
     "shell.execute_reply": "2022-08-27T11:12:56.115236Z"
    },
    "trusted": true
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:56.117903Z",
     "iopub.execute_input": "2022-08-27T11:12:56.118686Z",
     "iopub.status.idle": "2022-08-27T11:12:56.165215Z",
     "shell.execute_reply.started": "2022-08-27T11:12:56.118636Z",
     "shell.execute_reply": "2022-08-27T11:12:56.164253Z"
    },
    "trusted": true
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "select_feature = ['loading',\n",
    "                  'attribute_0',\n",
    "                  'measurement_17',\n",
    "                  'measurement_0',\n",
    "                  'measurement_1',\n",
    "                  'measurement_2',\n",
    "                  'area',\n",
    "                  'm3_missing',\n",
    "                  'm5_missing',\n",
    "                  'measurement_avg']"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:12:56.166586Z",
     "iopub.execute_input": "2022-08-27T11:12:56.167184Z",
     "iopub.status.idle": "2022-08-27T11:12:56.174811Z",
     "shell.execute_reply.started": "2022-08-27T11:12:56.167124Z",
     "shell.execute_reply": "2022-08-27T11:12:56.173712Z"
    },
    "trusted": true
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TabTransformer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:15:58.286286Z",
     "iopub.execute_input": "2022-08-27T11:15:58.286941Z",
     "iopub.status.idle": "2022-08-27T11:16:03.619737Z",
     "shell.execute_reply.started": "2022-08-27T11:15:58.286906Z",
     "shell.execute_reply": "2022-08-27T11:16:03.618730Z"
    },
    "trusted": true
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.columns"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "NUMERIC_FEATURE_NAMES = [i for i in df.columns]\n",
    "CATEGORICAL_FEATURES_WITH_VOCABULARY = {\n",
    "    'feature2':['1', '2']\n",
    "}\n",
    "\n",
    "\n",
    "CATEGORICAL_FEATURE_NAMES = list(CATEGORICAL_FEATURES_WITH_VOCABULARY.keys())\n",
    "FEATURE_NAMES = NUMERIC_FEATURE_NAMES + CATEGORICAL_FEATURE_NAMES\n",
    "COLUMN_DEFAULTS = [\n",
    "    [0.0] if feature_name in NUMERIC_FEATURE_NAMES else [\"NA\"]\n",
    "    for feature_name in FEATURE_NAMES\n",
    "]\n",
    "TARGET_FEATURE_NAME = \"label\"\n",
    "TARGET_LABELS = [\"0\", \"1\"]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:16:03.633560Z",
     "iopub.execute_input": "2022-08-27T11:16:03.634164Z",
     "iopub.status.idle": "2022-08-27T11:16:03.661937Z",
     "shell.execute_reply.started": "2022-08-27T11:16:03.634131Z",
     "shell.execute_reply": "2022-08-27T11:16:03.660865Z"
    },
    "trusted": true
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# perpare input"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def get_dataset_from_dataframe(data, batch_size=128, shuffle=False):\n",
    "    x, y = data\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dict(x), y)\n",
    "    )\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(len(x))\n",
    "    \n",
    "        \n",
    "    return dataset.batch(batch_size).cache()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:17:14.627600Z",
     "iopub.execute_input": "2022-08-27T11:17:14.628265Z",
     "iopub.status.idle": "2022-08-27T11:17:14.635005Z",
     "shell.execute_reply.started": "2022-08-27T11:17:14.628221Z",
     "shell.execute_reply": "2022-08-27T11:17:14.633732Z"
    },
    "trusted": true
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configure the hyperparameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "## optuna"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 0.0001\n",
    "DROPOUT_RATE = 0.2\n",
    "BATCH_SIZE = 265\n",
    "NUM_EPOCHS = 15\n",
    "\n",
    "NUM_TRANSFORMNUM_TRANSFORMER_BLOCKS = 3  \n",
    "ER_BLOCKS = 3  \n",
    "NUM_HEADS = 4  \n",
    "EMBEDDING_DIMS = 16  \n",
    "MLP_HIDDEN_UNITS_FACTORS = [\n",
    "    2,\n",
    "    1,\n",
    "]  \n",
    "NUM_MLP_BLOCKS = 2  "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:17:18.143032Z",
     "iopub.execute_input": "2022-08-27T11:17:18.143404Z",
     "iopub.status.idle": "2022-08-27T11:17:18.149285Z",
     "shell.execute_reply.started": "2022-08-27T11:17:18.143372Z",
     "shell.execute_reply": "2022-08-27T11:17:18.148111Z"
    },
    "trusted": true
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        if feature_name in NUMERIC_FEATURE_NAMES:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.float32\n",
    "            )\n",
    "        else:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.string\n",
    "            )\n",
    "    return inputs"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T11:17:52.017206Z",
     "iopub.execute_input": "2022-08-27T11:17:52.018119Z",
     "iopub.status.idle": "2022-08-27T11:17:52.023993Z",
     "shell.execute_reply.started": "2022-08-27T11:17:52.018083Z",
     "shell.execute_reply": "2022-08-27T11:17:52.022811Z"
    },
    "trusted": true
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Implement a training and evaluation procedure"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def run_experiment(\n",
    "    model,\n",
    "    train_data,\n",
    "    val_data,\n",
    "    test_data,\n",
    "    num_epochs,\n",
    "    learning_rate,\n",
    "    weight_decay,\n",
    "    batch_size,\n",
    "):\n",
    "\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[keras.metrics.AUC()],\n",
    "        run_eagerly=True,\n",
    "    )\n",
    "\n",
    "    train_dataset = get_dataset_from_dataframe(train_data, batch_size, shuffle=True)\n",
    "    validation_dataset = get_dataset_from_dataframe(val_data, batch_size)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices(dict(test_data)).batch(BATCH_SIZE).cache()\n",
    "    \n",
    "\n",
    "    print(\"Start training the model...\")\n",
    "    history = model.fit(\n",
    "        train_dataset, epochs=num_epochs, validation_data=validation_dataset\n",
    "    )\n",
    "    print(\"Model training finished\")\n",
    "\n",
    "    _, score = model.evaluate(validation_dataset, verbose=0)\n",
    "\n",
    "    print(f\"Validation AUC: {round(score * 100, 2)}%\")\n",
    "    \n",
    "    predict = model.predict(test_dataset)\n",
    "    #print(predict)\n",
    "    return history, np.array(predict).reshape(-1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T04:27:59.644677Z",
     "iopub.execute_input": "2022-08-27T04:27:59.647232Z",
     "iopub.status.idle": "2022-08-27T04:27:59.656417Z",
     "shell.execute_reply.started": "2022-08-27T04:27:59.647204Z",
     "shell.execute_reply": "2022-08-27T04:27:59.655449Z"
    },
    "trusted": true
   },
   "execution_count": 344,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create model inputs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        if feature_name in NUMERIC_FEATURE_NAMES:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.float32\n",
    "            )\n",
    "        else:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.string\n",
    "            )\n",
    "    return inputs"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T04:27:59.659704Z",
     "iopub.execute_input": "2022-08-27T04:27:59.660789Z",
     "iopub.status.idle": "2022-08-27T04:27:59.667032Z",
     "shell.execute_reply.started": "2022-08-27T04:27:59.660751Z",
     "shell.execute_reply": "2022-08-27T04:27:59.666098Z"
    },
    "trusted": true
   },
   "execution_count": 345,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Encode features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def encode_inputs(inputs, embedding_dims):\n",
    "\n",
    "    encoded_categorical_feature_list = []\n",
    "    numerical_feature_list = []\n",
    "\n",
    "    for feature_name in inputs:\n",
    "        if feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "            vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n",
    "\n",
    "\n",
    "            lookup = layers.StringLookup(\n",
    "                vocabulary=vocabulary,\n",
    "                mask_token=None,\n",
    "                num_oov_indices=0,\n",
    "                output_mode=\"int\",\n",
    "            )\n",
    "\n",
    "            encoded_feature = lookup(inputs[feature_name])\n",
    "\n",
    "            embedding = layers.Embedding(\n",
    "                input_dim=len(vocabulary), output_dim=embedding_dims\n",
    "            )\n",
    "\n",
    "            encoded_categorical_feature = embedding(encoded_feature)\n",
    "            encoded_categorical_feature_list.append(encoded_categorical_feature)\n",
    "\n",
    "        else:\n",
    "\n",
    "            numerical_feature = tf.expand_dims(inputs[feature_name], -1)\n",
    "            numerical_feature_list.append(numerical_feature)\n",
    "\n",
    "    return encoded_categorical_feature_list, numerical_feature_list"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T04:27:59.668824Z",
     "iopub.execute_input": "2022-08-27T04:27:59.669620Z",
     "iopub.status.idle": "2022-08-27T04:27:59.679666Z",
     "shell.execute_reply.started": "2022-08-27T04:27:59.669507Z",
     "shell.execute_reply": "2022-08-27T04:27:59.678494Z"
    },
    "trusted": true
   },
   "execution_count": 346,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Implement an MLP block"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def create_mlp(hidden_units, dropout_rate, activation, normalization_layer, name=None):\n",
    "\n",
    "    mlp_layers = []\n",
    "    for units in hidden_units:\n",
    "        mlp_layers.append(normalization_layer),\n",
    "        mlp_layers.append(layers.Dense(units, activation=activation))\n",
    "        mlp_layers.append(layers.Dropout(dropout_rate))\n",
    "\n",
    "    return keras.Sequential(mlp_layers, name=name)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T04:27:59.680846Z",
     "iopub.execute_input": "2022-08-27T04:27:59.682268Z",
     "iopub.status.idle": "2022-08-27T04:27:59.689728Z",
     "shell.execute_reply.started": "2022-08-27T04:27:59.682232Z",
     "shell.execute_reply": "2022-08-27T04:27:59.688767Z"
    },
    "trusted": true
   },
   "execution_count": 347,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_tabtransformer_classifier(\n",
    "    num_transformer_blocks,\n",
    "    num_heads,\n",
    "    embedding_dims,\n",
    "    mlp_hidden_units_factors,\n",
    "    dropout_rate,\n",
    "    use_column_embedding=False,\n",
    "):\n",
    "\n",
    "\n",
    "    inputs = create_model_inputs()\n",
    "    encoded_categorical_feature_list, numerical_feature_list = encode_inputs(\n",
    "        inputs, embedding_dims\n",
    "    )\n",
    "    encoded_categorical_features = tf.stack(encoded_categorical_feature_list, axis=1)\n",
    "    numerical_features = layers.concatenate(numerical_feature_list)\n",
    "\n",
    "\n",
    "    if use_column_embedding:\n",
    "        num_columns = encoded_categorical_features.shape[1]\n",
    "        column_embedding = layers.Embedding(\n",
    "            input_dim=num_columns, output_dim=embedding_dims\n",
    "        )\n",
    "        column_indices = tf.range(start=0, limit=num_columns, delta=1)\n",
    "        encoded_categorical_features = encoded_categorical_features + column_embedding(\n",
    "            column_indices\n",
    "        )\n",
    "\n",
    "    for block_idx in range(num_transformer_blocks):\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dims,\n",
    "            dropout=dropout_rate,\n",
    "            name=f\"multihead_attention_{block_idx}\",\n",
    "        )(encoded_categorical_features, encoded_categorical_features)\n",
    "        x = layers.Add(name=f\"skip_connection1_{block_idx}\")(\n",
    "            [attention_output, encoded_categorical_features]\n",
    "        )\n",
    "        x = layers.LayerNormalization(name=f\"layer_norm1_{block_idx}\", epsilon=1e-6)(x)\n",
    "        feedforward_output = create_mlp(\n",
    "            hidden_units=[embedding_dims],\n",
    "            dropout_rate=dropout_rate,\n",
    "            activation=keras.activations.gelu,\n",
    "            normalization_layer=layers.LayerNormalization(epsilon=1e-6),\n",
    "            name=f\"feedforward_{block_idx}\",\n",
    "        )(x)\n",
    "        x = layers.Add(name=f\"skip_connection2_{block_idx}\")([feedforward_output, x])\n",
    "        encoded_categorical_features = layers.LayerNormalization(\n",
    "            name=f\"layer_norm2_{block_idx}\", epsilon=1e-6\n",
    "        )(x)\n",
    "\n",
    "\n",
    "    categorical_features = layers.Flatten()(encoded_categorical_features)\n",
    "    numerical_features = layers.LayerNormalization(epsilon=1e-6)(numerical_features)\n",
    "    features = layers.concatenate([categorical_features, numerical_features])\n",
    "\n",
    "    mlp_hidden_units = [\n",
    "        factor * features.shape[-1] for factor in mlp_hidden_units_factors\n",
    "    ]\n",
    "    features = create_mlp(\n",
    "        hidden_units=mlp_hidden_units,\n",
    "        dropout_rate=dropout_rate,\n",
    "        activation=keras.activations.selu,\n",
    "        normalization_layer=layers.BatchNormalization(),\n",
    "        name=\"MLP\",\n",
    "    )(features)\n",
    "\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\", name=\"sigmoid\")(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "tabtransformer_model = create_tabtransformer_classifier(\n",
    "    num_transformer_blocks=NUM_TRANSFORMER_BLOCKS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    embedding_dims=EMBEDDING_DIMS,\n",
    "    mlp_hidden_units_factors=MLP_HIDDEN_UNITS_FACTORS,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    ")\n",
    "\n",
    "print(\"Total model weights:\", tabtransformer_model.count_params())\n",
    "keras.utils.plot_model(tabtransformer_model, show_shapes=True, rankdir=\"LR\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T04:27:59.693389Z",
     "iopub.execute_input": "2022-08-27T04:27:59.694434Z",
     "iopub.status.idle": "2022-08-27T04:28:03.392529Z",
     "shell.execute_reply.started": "2022-08-27T04:27:59.694392Z",
     "shell.execute_reply": "2022-08-27T04:28:03.391074Z"
    },
    "trusted": true
   },
   "execution_count": 348,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tabtransformer_model.summary()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T04:28:03.395732Z",
     "iopub.execute_input": "2022-08-27T04:28:03.396424Z",
     "iopub.status.idle": "2022-08-27T04:28:03.425531Z",
     "shell.execute_reply.started": "2022-08-27T04:28:03.396382Z",
     "shell.execute_reply": "2022-08-27T04:28:03.423945Z"
    },
    "trusted": true
   },
   "execution_count": 349,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "result = []\n",
    "for step,cross_val in enumerate([StratifiedKFold(n_splits=5, shuffle=True, random_state=0),GroupKFold(n_splits=5)]) :\n",
    "    print(f'\\n******** cross validation strategy : {cross_val} ********\\n')\n",
    "    lr_oof = np.zeros(len(train))\n",
    "    lr_test = np.zeros(len(test))\n",
    "    lr_auc = 0\n",
    "    importance_list = []\n",
    "    \n",
    "    kf = cross_val\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X, y,groups = train.product_code )):\n",
    "        \n",
    "        x_train, x_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        history, prdict = run_experiment(\n",
    "            model=tabtransformer_model,\n",
    "            train_data=(x_train, y_train),\n",
    "            val_data=(x_val, y_val),\n",
    "            test_data=test,\n",
    "            num_epochs=NUM_EPOCHS,\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            weight_decay=WEIGHT_DECAY,\n",
    "            batch_size=BATCH_SIZE,\n",
    "        )\n",
    "        result.append(prdict)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "result[0].shape"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T05:09:51.294091Z",
     "iopub.execute_input": "2022-08-27T05:09:51.294824Z",
     "iopub.status.idle": "2022-08-27T05:09:51.305270Z",
     "shell.execute_reply.started": "2022-08-27T05:09:51.294787Z",
     "shell.execute_reply": "2022-08-27T05:09:51.304095Z"
    },
    "trusted": true
   },
   "execution_count": 359,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "result_tab = np.mean(result, axis =0)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T05:09:44.912536Z",
     "iopub.execute_input": "2022-08-27T05:09:44.912897Z",
     "iopub.status.idle": "2022-08-27T05:09:44.919270Z",
     "shell.execute_reply.started": "2022-08-27T05:09:44.912868Z",
     "shell.execute_reply": "2022-08-27T05:09:44.918134Z"
    },
    "trusted": true
   },
   "execution_count": 357,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "result_tab.shape"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T05:09:45.723574Z",
     "iopub.execute_input": "2022-08-27T05:09:45.724577Z",
     "iopub.status.idle": "2022-08-27T05:09:45.731456Z",
     "shell.execute_reply.started": "2022-08-27T05:09:45.724531Z",
     "shell.execute_reply": "2022-08-27T05:09:45.730282Z"
    },
    "trusted": true
   },
   "execution_count": 358,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression¶"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# library for coding string values :\n",
    "! pip install feature_engine\n",
    "from feature_engine.encoding import WoEEncoder"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T05:09:54.867017Z",
     "iopub.execute_input": "2022-08-27T05:09:54.867419Z",
     "iopub.status.idle": "2022-08-27T05:10:04.313240Z",
     "shell.execute_reply.started": "2022-08-27T05:09:54.867386Z",
     "shell.execute_reply": "2022-08-27T05:10:04.311940Z"
    },
    "trusted": true
   },
   "execution_count": 360,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# #Thanks to @MAXSARMENTO \n",
    "woe_encoder = WoEEncoder(variables=['attribute_0'])\n",
    "woe_encoder.fit(X, y)\n",
    "X = woe_encoder.transform(X)\n",
    "test = woe_encoder.transform(test)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T05:10:04.317179Z",
     "iopub.execute_input": "2022-08-27T05:10:04.317498Z",
     "iopub.status.idle": "2022-08-27T05:10:04.387108Z",
     "shell.execute_reply.started": "2022-08-27T05:10:04.317468Z",
     "shell.execute_reply": "2022-08-27T05:10:04.386100Z"
    },
    "trusted": true
   },
   "execution_count": 361,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "result_0 = []\n",
    "result_1 = []\n",
    "for step,cross_val in enumerate([StratifiedKFold(n_splits=5, shuffle=True, random_state=0),GroupKFold(n_splits=5)]) :\n",
    "    print(f'\\n******** cross validation strategy : {cross_val} ********\\n')\n",
    "    lr_oof = np.zeros(len(train))\n",
    "    lr_test = np.zeros(len(test))\n",
    "    lr_auc = 0\n",
    "    importance_list = []\n",
    "    \n",
    "    kf = cross_val\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X, y,groups = train.product_code )):\n",
    "        x_train, x_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        #x_train, x_val, x_test = _scale(x_train, x_val, test, select_feature)\n",
    "\n",
    "        model = LogisticRegression(max_iter=200, C=0.0001, penalty='l2', solver='newton-cg')\n",
    "        model.fit(x_train[select_feature], y_train)\n",
    "        importance_list.append(model.coef_.ravel())\n",
    "\n",
    "        val_preds = model.predict_proba(x_val[select_feature])[:, 1]\n",
    "        print(\"FOLD: \", fold_idx+1, \" ROC-AUC:\", round(roc_auc_score(y_val, val_preds), 5))\n",
    "        lr_auc += roc_auc_score(y_val, val_preds) / 5\n",
    "        lr_test += model.predict_proba(test[select_feature])[:, 1] / 5\n",
    "        lr_oof[val_idx] = val_preds\n",
    "    \n",
    "    if step == 0:\n",
    "        result_0 = lr_test\n",
    "    else:\n",
    "        result_1 = lr_test\n",
    "    print(f\"\\n{Fore.GREEN}{Style.BRIGHT}Average auc = {round(lr_auc, 5)}{Style.RESET_ALL}\")\n",
    "    print(f\"{Fore.BLUE}{Style.BRIGHT}OOF auc     = {round(roc_auc_score(y, lr_oof), 5)}{Style.RESET_ALL}\\n\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T05:10:11.307851Z",
     "iopub.execute_input": "2022-08-27T05:10:11.308576Z",
     "iopub.status.idle": "2022-08-27T05:10:20.094126Z",
     "shell.execute_reply.started": "2022-08-27T05:10:11.308538Z",
     "shell.execute_reply": "2022-08-27T05:10:20.092739Z"
    },
    "trusted": true
   },
   "execution_count": 363,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Submission"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Remove id\n",
    "#test = test.drop('id', axis = 1)\n",
    "\n",
    "# LR GS  0.58786\n",
    "sub1 = sample_submission.copy()\n",
    "sub1.failure = (result_0 + result_1 + result_tab ) / 3 \n",
    "sub1.to_csv('submission.csv', index = False)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T05:10:37.047750Z",
     "iopub.execute_input": "2022-08-27T05:10:37.048163Z",
     "iopub.status.idle": "2022-08-27T05:10:37.106820Z",
     "shell.execute_reply.started": "2022-08-27T05:10:37.048131Z",
     "shell.execute_reply": "2022-08-27T05:10:37.105890Z"
    },
    "trusted": true
   },
   "execution_count": 365,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sub1.failure.describe()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T05:11:01.920505Z",
     "iopub.execute_input": "2022-08-27T05:11:01.921238Z",
     "iopub.status.idle": "2022-08-27T05:11:01.934693Z",
     "shell.execute_reply.started": "2022-08-27T05:11:01.921199Z",
     "shell.execute_reply": "2022-08-27T05:11:01.933658Z"
    },
    "trusted": true
   },
   "execution_count": 367,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "result_0"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T05:11:17.391731Z",
     "iopub.execute_input": "2022-08-27T05:11:17.392121Z",
     "iopub.status.idle": "2022-08-27T05:11:17.402838Z",
     "shell.execute_reply.started": "2022-08-27T05:11:17.392088Z",
     "shell.execute_reply": "2022-08-27T05:11:17.401555Z"
    },
    "trusted": true
   },
   "execution_count": 368,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
